{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f080e00",
   "metadata": {},
   "source": [
    "# 样例介绍\n",
    "* YOLOv5是一种单阶段目标检测算法，在这个样例中，我们选取了YOLOv5s，它是YOLOv5系列中较为轻量的网络，适合在边缘设备部署，进行实时目标检测。\n",
    "\n",
    "# 前期准备\n",
    "* 基础镜像的样例目录中已包含转换后的om模型以及测试图片，如果直接运行，可跳过此步骤。如果需要重新转换模型，可以参考下面的步骤。\n",
    "* 首先我们可以在[这个链接](https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Atlas%20200I%20DK%20A2/DevKit/downloads/23.0.RC1/Ascend-devkit_23.0.RC1_downloads.xlsx)的表格中找到本样例的依赖文件，下载我们已经准备好了的ONNX模型，ONNX是开源的离线推理模型框架。\n",
    "\n",
    "* 为了能进一步优化模型推理性能，我们需要将其转换为om模型进行使用，以下为转换指令：  \n",
    "    ```shell\n",
    "    atc --model=yolov5s.onnx --framework=5 --output=yolo --input_format=NCHW --input_shape=\"input_image:1,3,640,640\" --log=error --soc_version=Ascend310B1\n",
    "    ```\n",
    "    * 其中转换参数的含义为：  \n",
    "        * --model：输入模型路径\n",
    "        * --framework：原始网络模型框架类型，5表示ONNX\n",
    "        * --output：输出模型路径\n",
    "        * --input_format：输入Tensor的内存排列方式\n",
    "        * --input_shape：指定模型输入数据的shape\n",
    "        * --log：日志级别\n",
    "        * --soc_version：昇腾AI处理器型号\n",
    "        * --input_fp16_nodes：指定输入数据类型为FP16的输入节点名称\n",
    "        * --output_type：指定网络输出数据类型或指定某个输出节点的输出类型\n",
    "\n",
    "# 模型推理实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7761be-840e-4fc8-b501-7a5f9a0a56b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入代码依赖\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import torch\n",
    "from skvideo.io import vreader, FFmpegWriter\n",
    "import IPython.display\n",
    "from ais_bench.infer.interface import InferSession\n",
    "\n",
    "from det_utils import letterbox, scale_coords, nms,nms_ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aadc93a-7fd4-4765-8c2e-a09aaa158f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, cfg, bgr2rgb=True):\n",
    "    \"\"\"图片预处理\"\"\"\n",
    "    img, scale_ratio, pad_size = letterbox(image, new_shape=cfg['input_shape'])\n",
    "    if bgr2rgb:\n",
    "        img = img[:, :, ::-1]\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    img = img / 255.\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = np.concatenate((img[..., ::2, ::2], img[..., 1::2, ::2],\n",
    "                            img[..., ::2, 1::2], img[..., 1::2, 1::2]), axis=1)\n",
    "    img = torch.tensor(img,dtype=torch.float16)\n",
    "    return img, scale_ratio, pad_size\n",
    "\n",
    "def draw(img, pred):\n",
    "    img_ = img.copy()\n",
    "    if len(pred):\n",
    "        for detect in pred:\n",
    "            x1 = int(detect[0])\n",
    "            y1 = int(detect[1])\n",
    "            x2 = int(detect[0] + detect[2])\n",
    "            y2 = int(detect[1] + detect[3])\n",
    "            score = detect[4]\n",
    "            cls = detect[5]\n",
    "            labels = ['crack', 'crul', 'dent', 'material' ]\n",
    "            print(x1, y1, x2, y2, score, cls)\n",
    "            img_ = cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            text = labels[int(cls)] + ':' + str(score)\n",
    "            cv2.putText(img, text, (x1 + 25, y1 + 35), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, )\n",
    "    return img_\n",
    "\n",
    "\n",
    "def get_labels_from_txt(path):\n",
    "    \"\"\"从txt文件获取图片标签\"\"\"\n",
    "    labels_dict = dict()\n",
    "    with open(path) as f:\n",
    "        for cat_id, label in enumerate(f.readlines()):\n",
    "            labels_dict[cat_id] = label.strip()\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def draw_prediction(pred, image, labels):\n",
    "    \"\"\"在图片上画出预测框并进行可视化展示\"\"\"\n",
    "    imgbox = widgets.Image(format='jpg', height=640, width=640)\n",
    "    img_dw = draw(image,pred)\n",
    "    #imgbox.value = cv2.imencode('.jpg', img_dw)[1].tobytes()\n",
    "    ##display(imgbox)\n",
    "    display(img_dw)\n",
    "\n",
    "\n",
    "def infer_image(img_path, model, class_names, cfg):\n",
    "    \"\"\"图片推理\"\"\"\n",
    "    # 图片载入\n",
    "    image = cv2.imread(img_path)\n",
    "    # 数据预处理\n",
    "    img, scale_ratio, pad_size = preprocess_image(image, cfg)\n",
    "    orig_h = 320.0\n",
    "    orig_w = 320.0\n",
    "    # 模型推理\n",
    "    print(img.shape)\n",
    "    output = model.infer([img])\n",
    "    #output = torch.tensor(output)\n",
    "    output_big = output[0]\n",
    "    output_me = output[1]\n",
    "    output_small = output[2]\n",
    "    print(output_small.shape,'output_small')\n",
    "    print(output_me.shape,'output_me')\n",
    "    print(output_big.shape,'output_big')\n",
    "    output_small = np.squeeze(output_small)\n",
    "    output_small = np.reshape(output_small, [19200, 85])\n",
    "    output_me = np.squeeze(output_me)\n",
    "    output_me = np.reshape(output_me, [4800, 85])\n",
    "    output_big = np.squeeze(output_big)\n",
    "    output_big = np.reshape(output_big, [1200, 85])\n",
    "    result = np.vstack([output_small, output_me, output_big])\n",
    "    for i in range(len(result)):\n",
    "        x = result[i][0] * orig_w\n",
    "        y = result[i][1] * orig_h\n",
    "        w = result[i][2] * orig_w\n",
    "        h = result[i][3] * orig_h\n",
    "        x_top_left = x - w / 2.\n",
    "        y_top_left = y - h / 2.\n",
    "        x_left, y_left = max(0, x_top_left), max(0, y_top_left)\n",
    "        wi, hi = min(orig_w, w), min(orig_h, h)\n",
    "        result[i][0], result[i][1], result[i][2], result[i][3] = x_left, y_left, wi, hi\n",
    "    #result = torch.tensor(result)\n",
    "    # 非极大值抑制后处理\n",
    "    boxout = nms_ours(result, conf_thres=cfg[\"conf_thres\"], iou_thres=cfg[\"iou_thres\"])\n",
    "    pred_all = boxout\n",
    "    # 预测坐标转换\n",
    "    #scale_coords(cfg['input_shape'], pred_all[:, :4], image.shape, ratio_pad=(scale_ratio, pad_size))\n",
    "    # 图片预测结果可视化\n",
    "    #draw_prediction(pred_all, image, class_names)\n",
    "    imgbox = widgets.Image(format='jpg', height=640, width=640)\n",
    "    img_dw = draw(image,pred_all)\n",
    "    imgbox.value = cv2.imencode('.jpg', img_dw)[1].tobytes()\n",
    "    display(imgbox)\n",
    "    cv2.imwrite('results.jpg',img_dw)\n",
    "\n",
    "def infer_frame_with_vis(image, model, labels_dict, cfg, bgr2rgb=True):\n",
    "    # 数据预处理\n",
    "    img, scale_ratio, pad_size = preprocess_image(image, cfg, bgr2rgb)\n",
    "    # 模型推理\n",
    "    output = model.infer([img])[0]\n",
    "    output = torch.tensor(output)\n",
    "    print(output)\n",
    "    # 非极大值抑制后处理\n",
    "    boxout = nms(output, conf_thres=cfg[\"conf_thres\"], iou_thres=cfg[\"iou_thres\"])\n",
    "    pred_all = boxout[0].numpy()\n",
    "    # 预测坐标转换\n",
    "    scale_coords(cfg['input_shape'], pred_all[:, :4], image.shape, ratio_pad=(scale_ratio, pad_size))\n",
    "    # 图片预测结果可视化\n",
    "    img_vis = draw_bbox(pred_all, image, (0, 255, 0), 2, labels_dict)\n",
    "    return img_vis\n",
    "\n",
    "\n",
    "def img2bytes(image):\n",
    "    \"\"\"将图片转换为字节码\"\"\"\n",
    "    return bytes(cv2.imencode('.jpg', image)[1])\n",
    "\n",
    "\n",
    "def infer_video(video_path, model, labels_dict, cfg):\n",
    "    \"\"\"视频推理\"\"\"\n",
    "    image_widget = widgets.Image(format='jpeg', width=800, height=600)\n",
    "    display(image_widget)\n",
    "\n",
    "    # 读入视频\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while True:\n",
    "        ret, img_frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # 对视频帧进行推理\n",
    "        image_pred = infer_frame_with_vis(img_frame, model, labels_dict, cfg, bgr2rgb=True)\n",
    "        image_widget.value = img2bytes(image_pred)\n",
    "\n",
    "\n",
    "def infer_camera(model, labels_dict, cfg):\n",
    "    \"\"\"外设摄像头实时推理\"\"\"\n",
    "    def find_camera_index():\n",
    "        max_index_to_check = 10  # Maximum index to check for camera\n",
    "\n",
    "        for index in range(max_index_to_check):\n",
    "            cap = cv2.VideoCapture(index)\n",
    "            if cap.read()[0]:\n",
    "                cap.release()\n",
    "                return index\n",
    "\n",
    "        # If no camera is found\n",
    "        raise ValueError(\"No camera found.\")\n",
    "\n",
    "    # 获取摄像头\n",
    "    camera_index = find_camera_index()\n",
    "    cap = cv2.VideoCapture(camera_index)\n",
    "    # 初始化可视化对象\n",
    "    image_widget = widgets.Image(format='jpeg', width=1280, height=720)\n",
    "    display(image_widget)\n",
    "    while True:\n",
    "        # 对摄像头每一帧进行推理和可视化\n",
    "        _, img_frame = cap.read()\n",
    "        image_pred = infer_frame_with_vis(img_frame, model, labels_dict, cfg)\n",
    "        image_widget.value = img2bytes(image_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e455e8d",
   "metadata": {},
   "source": [
    "# 样例运行\n",
    "\n",
    "* 初始化相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccded13-fad1-4b88-b63f-d46deb23aa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'conf_thres': 0.25,  # 模型置信度阈值，阈值越低，得到的预测框越多\n",
    "    'iou_thres': 0.4,  # IOU阈值，高于这个阈值的重叠预测框会被过滤掉\n",
    "    'input_shape': [640,640],  # 模型输入尺寸\n",
    "}\n",
    "\n",
    "model_path = 'ourfour.om'\n",
    "label_path = './ours_name.txt'\n",
    "# 初始化推理模型\n",
    "model = InferSession(0, model_path)\n",
    "labels_dict = get_labels_from_txt(label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e9cf34",
   "metadata": {},
   "source": [
    "* 选择推理模式。\"infer_mode\"有三个取值：image, camera, video，分别对应图片推理、摄像头实时推理和视频推理。默认使用视频推理模式。\n",
    "* 我们选取的样例是一个赛车视频，执行下面的代码后可以看到模型会对视频的每一帧进行推理，并将预测结果展示在画面上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab68b6b-7d65-4dd9-ab0b-c5c9733c415a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infer_mode = 'image'\n",
    "if infer_mode == 'image':\n",
    "    img_path = '320.jpg'\n",
    "    infer_image(img_path, model, labels_dict, cfg)\n",
    "elif infer_mode == 'camera':\n",
    "    infer_camera(model, labels_dict, cfg)\n",
    "elif infer_mode == 'video':\n",
    "    video_path = 'racing.mp4'\n",
    "    infer_video(video_path, model, labels_dict, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27887b77",
   "metadata": {},
   "source": [
    "# \n",
    "样例总结与扩展\n",
    "以上就是这个样例的全部内容了，值得关注的是在模型推理后有一步非常重要的后处理，就是非极大值抑制，即NMS，由于模型的原始预测结果会有非常多无效或重叠的预测框，我们需要通过NMS来进行过滤。再者，模型预测框的表示往往是一个标准化的结果，比如0到1之间，我们需要通过坐标转换将结果与原始图片的宽高对应上。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('torch-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7df911660de2913d6d886b127abd0b83476325e16e88df6d5b8af7a43067a865"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
